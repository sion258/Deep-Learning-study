{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "色泽\t根蒂\t敲声\t纹理\t脐部\t触感\t好瓜（y）\n",
    "0\t0\t0\t0\t0\t0\t1\n",
    "1\t0\t0\t0\t0\t0\t1\n",
    "2\t0\t0\t0\t0\t0\t1\n",
    "0\t1\t1\t0\t1\t1\t0\n",
    "1\t1\t1\t1\t1\t1\t0\n",
    "2\t1\t1\t1\t1\t0\t0\n",
    "0\t2\t2\t2\t2\t1\t0\n",
    "1\t2\t2\t1\t2\t0\t0\n",
    "2\t2\t2\t2\t2\t1\t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index = None, feature_val=None, left=None, right=None,value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.feature_val = feature_val\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "\n",
    "\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, criterion = 'gini', max_deepth = None, min_sample_split = None, root = None):\n",
    "        self.root = root\n",
    "        self.criterion = criterion\n",
    "        self.max_deepth = max_deepth\n",
    "        self.min_sample_split = 2\n",
    "\n",
    "    def _caculate_gini(self, X, y, feature_index, feature_val):\n",
    "        '''\n",
    "        计算基尼指数，\n",
    "        基尼值：计算所有标签的1-p_k^2之和,\n",
    "        基尼指数：在每个属性（feature_index）下根据属性值(feature_val)分配权重计算基尼值之和\n",
    "        '''\n",
    "        left = X[:, feature_index] <= feature_val\n",
    "        right = X[:, feature_index] > feature_val\n",
    "        y_left, y_right = y[left], y[right]\n",
    "        # 计算基尼值\n",
    "        def gini(y_subset):\n",
    "           classes, counts = np.unique(y_subset, return_counts = True)\n",
    "           p_k = counts / len(y_subset)\n",
    "           gini_val = 1 - sum(p_k** 2)\n",
    "           return gini_val\n",
    "        \n",
    "        left_gini = gini(y_left)\n",
    "        right_gini = gini(y_right)\n",
    "\n",
    "        #计算加权值\n",
    "        total_gini = (len(y_left)/len(y))*left_gini+(len(y_right)/len(y))*right_gini\n",
    "\n",
    "        return total_gini\n",
    "    \n",
    "    def _split_node(self, X, y, criterion = 'gini'):\n",
    "        '''\n",
    "        将X进行划分，根据gini指数等，返回最佳划分方案，\n",
    "        为一个包含gini指数，最佳划分属性编号和最佳划分属性值的的三元组\n",
    "        '''\n",
    "        best_criterion = float('inf') if criterion == 'gini' else -float('inf')\n",
    "        best_feature_index = None\n",
    "        best_feature_val = None\n",
    "\n",
    "        _,n_features = X.shape\n",
    "\n",
    "        for feature_index in range(n_features):\n",
    "            feature_vals = np.unique(X[:,feature_index])\n",
    "            # 如果判断其是gini指数\n",
    "            for feature_val in feature_vals:\n",
    "                if criterion == 'gini':\n",
    "                    gini = self._caculate_gini(X, y, feature_index, feature_val)\n",
    "                    \n",
    "                    # 更新最优划分\n",
    "                    if gini < best_criterion:\n",
    "                        best_criterion = gini\n",
    "                        best_feature_index = feature_index\n",
    "                        best_feature_val = feature_val\n",
    "                # 如果判断器是gain增益率\n",
    "                elif criterion == 'gain':\n",
    "                    gain = self._caculate_gain(X, y, feature_index, feature_val)\n",
    "                    \n",
    "                    # 更新最优划分\n",
    "                    if gain > best_criterion:\n",
    "                        best_criterion = gain\n",
    "                        best_feature_index = feature_index\n",
    "                        best_feature_val = feature_val\n",
    "\n",
    "        return best_criterion, best_feature_index,best_feature_val\n",
    "    \n",
    "\n",
    "    \n",
    "    def _most_common_label(self, y):\n",
    "        return np.bincount(y).argmax()\n",
    "    \n",
    "    def _build_tree(self, X, y, depth = 0, pred = 0):\n",
    "        '''\n",
    "        构建树,传入特征向量X和标签向量y\n",
    "        \n",
    "        '''\n",
    "        # 首先设置停止划分的条件，叶子节点保存输出类别，类别为当前标签集合中最常见的标签\n",
    "        n_samples, n_features = X.shape# 行数正好是数据总数，列数为属性的总数目\n",
    "        n_labels = len(np.unique(y))\n",
    "\n",
    "        if n_labels == 1 or depth >= self.max_deepth or n_samples < self.min_sample_split:\n",
    "            leaf_val = self._most_common_label(y)\n",
    "            return Node(value=leaf_val)\n",
    "        \n",
    "        # 开始划分\n",
    "        _, feature_index, feature_val = self._split_node(X, y, 'gini')\n",
    "\n",
    "\n",
    "        # 设置划分的开始编号\n",
    "        left_idx = X[:,feature_index] <= feature_val\n",
    "        right_idx = X[:,feature_index] > feature_val\n",
    "\n",
    "        left_pred = np.sum(y[left_idx] == 0) / len(y[left_idx])\n",
    "        right_pred = np.sum(y[right_idx] == 0) / len(y[right_idx])\n",
    "\n",
    "        # 预剪枝，递归处理左右子集\n",
    "        if pred >= left_pred and pred >= right_pred:\n",
    "            leaf_val = self._most_common_label(y)\n",
    "            return Node(value=leaf_val)\n",
    "        else:\n",
    "            left = self._build_tree(X[left_idx,:],y[left_idx], depth+1, left_pred)\n",
    "            right = self._build_tree(X[right_idx,:], y[right_idx],depth+1, right_pred)\n",
    "\n",
    "            if left is None and right is None:\n",
    "                leaf_val = self._most_common_label(y)\n",
    "                return Node(value=leaf_val)\n",
    "\n",
    "        # 返回树结构\n",
    "        return Node(feature_index=feature_index,feature_val=feature_val,left=left, right=right)\n",
    "    \n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        '''\n",
    "        遍历树以匹配输入数据x的输出标签类别\n",
    "        '''\n",
    "\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        \n",
    "        if x[node.feature_index] <= node.feature_val:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    \n",
    "    # 评估精度\n",
    "    def _evaluate_tree(self, X_val, y_val):\n",
    "        predictions = [self._traverse_tree(x, self.root) for x in X_val]\n",
    "        return accuracy_score(y_val, predictions)\n",
    "\n",
    "    # 后剪枝\n",
    "    def _prune_tree(self, node, X_val, y_val):\n",
    "        if node is None:\n",
    "            return None\n",
    "        \n",
    "        # 递归地剪枝左子树和右子树\n",
    "        node.left = self._prune_tree(node.left, X_val, y_val)\n",
    "        node.right = self._prune_tree(node.right, X_val, y_val)\n",
    "        \n",
    "        # 如果当前节点的左右子树都为空，返回当前节点\n",
    "        if node.left is None and node.right is None:\n",
    "            return node\n",
    "        \n",
    "        # 获取当前节点的值\n",
    "        new_leaf_val = node.value\n",
    "        \n",
    "        # 如果左右子树都存在，则尝试剪枝\n",
    "        if node.left is not None and node.right is not None:\n",
    "            # 保存原始树\n",
    "            original_tree = self\n",
    "            \n",
    "            # 创建一个新的叶子节点，其值为当前节点的值\n",
    "            new_node = Node(value=new_leaf_val)\n",
    "            self.root = new_node\n",
    "            \n",
    "            # 计算剪枝前后模型在验证集上的准确度\n",
    "            if self._evaluate_tree(X_val, y_val) > self._evaluate_tree(original_tree, X_val, y_val):\n",
    "                # 如果剪枝后的树在验证集上的表现更好，返回新的叶子节点\n",
    "                return new_node\n",
    "            else:\n",
    "                # 否则，恢复原始树并返回原始节点\n",
    "                self.root = node\n",
    "        \n",
    "        return node\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, X_val = None, y_val = None, prune = False):\n",
    "        self.root = self._build_tree(X,y) #将树保存再在root中\n",
    "        if prune and X_val is not None and y_val is not None:\n",
    "            self._prune_tree(self.root, X_val, y_val)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._traverse_tree(x, self.root) for x in X]  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],  # 青绿, 蜷缩, 浊响, 清晰, 凹陷, 硬滑\n",
    "    [1, 0, 0, 0, 0, 0],  # 乌黑, 蜷缩, 浊响, 清晰, 凹陷, 硬滑\n",
    "    [2, 0, 0, 0, 0, 0],  # 浅白, 蜷缩, 浊响, 清晰, 凹陷, 硬滑\n",
    "    [0, 1, 1, 0, 1, 1],  # 青绿, 稍蜷, 沉闷, 清晰, 稍凹, 软粘\n",
    "    [1, 1, 1, 1, 1, 1],  # 乌黑, 稍蜷, 沉闷, 稍糊, 稍凹, 软粘\n",
    "    [2, 1, 1, 1, 1, 0],  # 浅白, 稍蜷, 沉闷, 稍糊, 稍凹, 硬滑\n",
    "    [0, 2, 2, 2, 2, 1],  # 青绿, 硬挺, 清脆, 模糊, 平坦, 软粘\n",
    "    [1, 2, 2, 1, 2, 0],  # 乌黑, 硬挺, 清脆, 稍糊, 平坦, 硬滑\n",
    "    [2, 2, 2, 2, 2, 1]   # 浅白, 硬挺, 清脆, 模糊, 平坦, 软粘\n",
    "])\n",
    "\n",
    "# 标签向量 y\n",
    "y = np.array([1, 1, 1, 0, 0, 0, 0, 0, 0])  # 1: 好瓜, 0: 坏瓜\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)\n",
    "\n",
    "clf = DecisionTree(max_deepth=3)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
